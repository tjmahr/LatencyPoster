# Exploring the latency data

This `Rmd` file is where I try to figure out what's going on in the data.




```{r, results='hide', message=FALSE, warning=FALSE}
# Load the latency data
setwd("../")
source('R/01_functions.r', chdir = TRUE)
load("data/results.RData")
```

```{r, message=FALSE, warning=FALSE, echo =FALSE}
# Functions for frequently used queries
ComputePercentNA <- function(results) {
  results$NotNA <- ifelse(is.na(results$Latency), 0, 1)
  not_na <- dcast(results, Version ~ NotNA, value.var = "NotNA")
  names(not_na) <- c("Version", "NAs", "Real")
  not_na <- transform(not_na, PercentNA = round((NAs / (NAs + Real)) * 100, 2))
  names(not_na) <- c("Version", "NA Latencies", "Real Latencies", "Percent NA")
  PrettyPrint(not_na)
}

PrintDescriptives <- function(results) {
  descriptives <- describeBy(results$Latency, group=results$Version, mat=T, skew=F)
  rownames(descriptives) <- c("CS1", "CS2")
  # Convert to a dataframe for table-printing
  descriptives <- t(descriptives)[-c(1:3), ]
  descriptives <- as.data.frame(descriptives)
  PrettyPrint(descriptives)
}

TrimTooFast <- function(results, cutoff = 250) {
  results$TooFast <- round(results$Latency) <= cutoff
  # How many latencies were too fast within each group
  too_fast <- dcast(results, Version ~ TooFast)
  names(too_fast) <- sprintf(c("Version", "Num > %1.f ms", "Num <= %1.f ms", "Num NA"), cutoff)
  PrettyPrint(too_fast)
  # Store some facts about the trimming
  attr(results, "TrimmedFast") <- length(which(round(results$Latency) < cutoff))
  attr(results, "FastCutOff") <- cutoff
  # Replace too-fast latencies with NA values
  results$Latency[round(results$Latency) < cutoff] <- NA  
  results$TooFast <- NULL
  results
}

TrimTooSlow <- function(results, sd_cutoff = 2) {
  sd_limit <- sd_cutoff * sd(results$Latency, na.rm = TRUE)
  cutoff <- mean(results$Latency, na.rm = TRUE) + sd_limit
  results$TooSlow <- round(results$Latency) >= cutoff
  # How many latencies were too slow within each group
  too_slow <- dcast(results, Version ~ TooSlow)
  names(too_slow) <- sprintf(c("Version", "Num < %1.f ms", "Num > %1.f ms", "Num NA"), cutoff)
  PrettyPrint(too_slow)
  # Store information about the trimming
  attr(results, "TrimmedSlow") <- length(which(results$Latency > cutoff))
  attr(results, "SlowCutOff") <- cutoff
  # Trim slow values
  results$Latency[results$Latency > too_slow] <- NA
  results$TooSlow <- NULL
  results
}

PrettyPrint <- function(x) suppressWarnings(print(ascii(x), type = "pandoc"))
```



## Reponses to JE's email:

### _For methods, can you write bullet points on how we calculated latencies?_

Reaction times measure the latency between looking to the distractor image and shifting the gaze towards the target image after the onset of the target word. The following conditions were required for the latency calculation:

* During the first 50 ms of the target word, the child had to be looking onscreen, but not at the target image.
* The first look to the target must occur afte 250r ms. (That is, shifts of looks towards the target before 250 ms were considered too fast to be deliberate responses to the target word.)



### _After trimming, what % of trials had latencies in CS1? In CS2? Are there more trials with latencies in CS2 compared to CS1 after trimming, as there were before trimming?_

Here are the summary stats for the unadjusted values. First, we remove subjects who have been designated as non-keepers. We also remove subjects who were tested with the AAE dialect stimuli, since those audio stimuli were not the same duration.

```{r, results='asis', message=FALSE}
results <- subset(results, is.na(Keeper) & Dialect == "SAE")
PrintDescriptives(results)
```
Table: Descriptives for unadjusted latency values


```{r, results='asis', message=FALSE}
ComputePercentNA(results)
```
Table: Response rates for the experiment versions, before trimming.

Now we trim of the too-fast values using 250 ms as the cut-off.

```{r, results='asis', message=FALSE}
results <- TrimTooFast(results, cutoff = 250)
```


The upper-bound of the trimming depends on what pool of latencies are used to compute the standard deviation used for the 2-SD cut-off.

```{r}
ComputeUpperBound <- function(x) mean(x, na.rm = T) + (2 * sd(x, na.rm = T))
DropAboveUpperBound <- function(df) {
  cutoff <- ComputeUpperBound(df$Latency)
  df$Latency[df$Latency > cutoff] <- NA
  df
}

# Pooling both experiments together
ComputeUpperBound(results$Latency)
# Separating the two experiments
by(results$Latency, results$Version, ComputeUpperBound)
cs1 <- subset(results, Version == "CS1")
cs1 <- DropAboveUpperBound(cs1)
cs2 <- subset(results, Version == "CS2")
cs2 <- DropAboveUpperBound(cs2)
results <- rbind(cs1, cs2)
```

```{r, results='asis', message=FALSE, warning=FALSE}
PrintDescriptives(results)
```
Table: Descriptives for trimmed latency values. Upper bounds were trimmed within each experimnet.

```{r, results='asis', message=FALSE}
ComputePercentNA(results)
```
Table: Response rates for the experiment versions, after trimming.

### _After trimming, is the average latency shorter for CS2 as compared to CS1? (as it was before trimming)?_

Yes.

### _Is there a relationship between vocab size (either EVT-2 raw score of PPVT-4 raw score) and latency for CS1?_

I'm going to compute the average latency within each subject and plot latency as a function of EVT and PPVT.

```{r}
subject_means <- ddply(results, "Subject", summarize, 
                       Version = unique(Version), EVT = unique(EVT), PPVT = unique(PPVT),
                       Latency = mean(Latency, na.rm = TRUE))
cs1 <- subset(subject_means, Version == "CS1")
# EVT
qplot(data = cs1, x = EVT, y = Latency) + geom_smooth(method = "lm")
# PPVT 
qplot(data = cs1, x = PPVT, y = Latency) + geom_smooth(method = "lm")
```


### _Same question for CS2?_

For the aggregated values, there is some correlation between EVT and latency.

```{r}
cs2 <- subset(subject_means, Version == "CS2")
# EVT
qplot(data = cs2, x = EVT, y = Latency) + geom_smooth(method = "lm")
# PPVT 
qplot(data = cs2, x = PPVT, y = Latency) + geom_smooth(method = "lm")
summary(lm(Latency ~ EVT, cs2))
```



