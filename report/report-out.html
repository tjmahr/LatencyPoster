<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
</head>
<body>
<h1 id="do-orienting-stimuli-create-additional-task-demands-in-the-looking-while-listening-paradigm">Do orienting stimuli create additional task demands in the looking-while-listening paradigm?</h1>
<h2 id="introduction">Introduction</h2>
<p>The looking-while-listening paradigm <span class="citation" data-cites="FernaldLWL">(LWL; Fernald, Zangl, Portillo, &amp; Marchman, 2008)</span> uses eye-tracking to study lexical comprehension in young children. In this procedure, two images are presented on a computer screen followed by a prompt to look at one of the images. The data gathered through eye-tracking not only records <em>where</em> the child looks onscreen but <em>when</em> the child fixates on a particular image. The latency between the onset of a speech stimulus and an appropriate change of gaze location provides a measure of how rapidly the child accesses the word's lexical representation. Reaction time is related to vocabulary size in young children and is also predictive of later language abilities <span class="citation" data-cites="FernaldHalfAWord MarchmanLangOutcomes">(Fernald, Swingley, &amp; Pinto, 2001; Marchman &amp; Fernald, 2008)</span>.</p>
<p>Reaction times provide valuable information about the real-time processing of speech signal in children, but these data are not easily obtained. In a 2-alternative forced choice (2AFC) LWL paradigm, there is a 50% chance the child will be fixated on the target image at onset of the speech stimulus, so only half the trials will provide latency data. This problem is readily resolved in studies with adults by instructing participants to fixate on a central orienting image until they hear the stimulus. Unfortunately, young children cannot be similarly instructed.</p>
<p>In this study, we modified the LWL paradigm to include an animated centering stimulus in order to increase the number of trials with meaningful reaction time data. We hypothesized that the orienting animations will increase the &quot;quality&quot; of the eye-tracking data but may also introduce additional task demands that hinder response time and reduce accuracy.</p>
<h2 id="methods">Methods</h2>
<h3 id="participants">Participants</h3>
<p>The participants were fifty 30-- to 48-month-old children, 25 per condition (with and without the central fixation point). All participants passed a hearing screening and had age-appropriate speech and language, according to parent report.</p>
<h3 id="procedure">Procedure</h3>
<p>A 2AFC mispronunciation experiment was used in condition. In this experiment, children saw pictures of a familiar and an unfamiliar object and heard three types of stimuli in a carrier phrase: familiar real words, one-feature mispronunciations (<em>dog</em> vs. <em>tog</em>), and nonwords (/veif/). Children also received an expressive vocabulary test (EVT-2, Williams, 2007).</p>
<h3 id="statistical-analysis">Statistical Analysis</h3>
<p>The log-odds of looking to the familiar object was the dependent variable. We used a growth curve model to model how children’s eye gaze patterns were related to their expressive vocabulary size (Mirman et al., 2008)</p>
<h2 id="results-and-discussion">Results and Discussion</h2>
<hr />
<h2 id="scratch-area-for-testing-things-out">Scratch area for testing things out</h2>
<p><strong>Ciations</strong></p>
<ul>
<li><span class="citation" data-cites="BaayenRTs">Baayen &amp; Milin (2010)</span> recommend blah blah blah.</li>
<li>We try the inverse-normal distribution <span class="citation" data-cites="BaayenRTs">(Baayen &amp; Milin, 2010)</span>,</li>
</ul>
<p><strong>Embed an image!</strong></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(cars)</code></pre>
<figure>
<img src="figure/unnamed-chunk-1.png" alt="Test image" /><figcaption>Test image</figcaption>
</figure>
<p><strong>Tables?</strong></p>
<p>Use the <code>ascii</code> package to make a captioned Pandoc table:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ascii)
<span class="kw">data</span>(esoph)
<span class="kw">print</span>(<span class="kw">ascii</span>(esoph[<span class="dv">1</span>:<span class="dv">10</span>, ]), <span class="dt">type =</span> <span class="st">&quot;pandoc&quot;</span>)</code></pre>
<table>
<caption>This is a table caption.</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;"><strong>agegp</strong></th>
<th style="text-align: left;"><strong>alcgp</strong></th>
<th style="text-align: left;"><strong>tobgp</strong></th>
<th style="text-align: left;"><strong>ncases</strong></th>
<th style="text-align: left;"><strong>ncontrols</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">1</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">0-39g/day</td>
<td style="text-align: left;">0-9g/day</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">40.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">2</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">0-39g/day</td>
<td style="text-align: left;">10-19</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">10.00</td>
</tr>
<tr class="odd">
<td style="text-align: left;">3</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">0-39g/day</td>
<td style="text-align: left;">20-29</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">6.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">4</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">0-39g/day</td>
<td style="text-align: left;">30+</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">5.00</td>
</tr>
<tr class="odd">
<td style="text-align: left;">5</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">40-79</td>
<td style="text-align: left;">0-9g/day</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">27.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">6</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">40-79</td>
<td style="text-align: left;">10-19</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">7.00</td>
</tr>
<tr class="odd">
<td style="text-align: left;">7</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">40-79</td>
<td style="text-align: left;">20-29</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">4.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">8</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">40-79</td>
<td style="text-align: left;">30+</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">7.00</td>
</tr>
<tr class="odd">
<td style="text-align: left;">9</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">80-119</td>
<td style="text-align: left;">0-9g/day</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">2.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">10</td>
<td style="text-align: left;">25-34</td>
<td style="text-align: left;">80-119</td>
<td style="text-align: left;">10-19</td>
<td style="text-align: left;">0.00</td>
<td style="text-align: left;">1.00</td>
</tr>
</tbody>
</table>
<h2 id="references">References</h2>
<p>Baayen, R. H., &amp; Milin, P. (2010). Analysing Reaction Times. <em>International Journal of Psychological Research</em>, <em>3</em>(2), 12–28.</p>
<p>Fernald, A., Swingley, D., &amp; Pinto, J. P. (2001). When Half a Word Is Enough: Infants Can Recognize Spoken Words Using Partial Phonetic Information. <em>Child Development</em>, <em>72</em>(4), 1003–1015. doi:10.1111/1467-8624.00331</p>
<p>Fernald, A., Zangl, R., Portillo, A. L., &amp; Marchman, V. A. (2008). Looking while listening: Using eye movements to monitor spoken language comprehension by infants and young children. In I. A. Sekerina, E. M. Fernández, &amp; H. Clahsen (Eds.), <em>Developmental Psycholinguistics: On-line Methods in Children’s Language Processing</em> (pp. 97–135). Amsterdam: John Benjamins Publishing Company.</p>
<p>Marchman, V. A., &amp; Fernald, A. (2008). Speed of word recognition and vocabulary knowledge in infancy predict cognitive and language outcomes in later childhood. <em>Developmental Science</em>, <em>11</em>(3), F9–F16. doi:10.1111/j.1467-7687.2008.00671.x</p>
</body>
</html>
