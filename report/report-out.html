<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
</head>
<body>
<h1 id="do-orienting-stimuli-create-additional-task-demands-in-the-looking-while-listening-paradigm">Do orienting stimuli create additional task demands in the looking-while-listening paradigm?</h1>
<h2 id="introduction">Introduction</h2>
<p>The looking-while-listening paradigm <span class="citation" data-cites="FernaldLWL">(LWL; Fernald, Zangl, Portillo, &amp; Marchman, 2008)</span> uses eye-tracking to study lexical comprehension in young children. In this procedure, two images are presented on a computer screen followed by a prompt to look at one of the images. The data gathered through eye-tracking not only records <em>where</em> the child looks onscreen but <em>when</em> the child fixates on a particular image. The latency between the onset of a speech stimulus and an appropriate change of gaze location provides a measure of how rapidly the child accesses the word's lexical representation. Reaction time is related to vocabulary size in young children and is also predictive of later language abilities <span class="citation" data-cites="FernaldHalfAWord MarchmanLangOutcomes">(Fernald, Swingley, &amp; Pinto, 2001; Marchman &amp; Fernald, 2008)</span>.</p>
<p>Reaction times provide valuable information about the real-time processing of speech signal in children, but these data are not easily obtained. In a 2-alternative forced choice (2AFC) LWL paradigm, there is a 50% chance the child will be fixated on the target image at onset of the speech stimulus, so only half the trials will provide latency data. This problem is readily resolved in studies with adults by instructing participants to fixate on a central orienting image until they hear the stimulus. Unfortunately, young children cannot be similarly instructed.</p>
<p>In this study, we modified the LWL paradigm to include an animated centering stimulus in order to increase the number of trials with meaningful reaction time data. We hypothesized that the orienting animations will increase the &quot;quality&quot; of the eye-tracking data but may also introduce additional task demands that hinder response time and reduce accuracy.</p>
<hr />
<p><span class="citation" data-cites="BaayenRTs">Baayen &amp; Milin (2010)</span> recommend blah blah blah.</p>
<p>We try the inverse-normal distribution <span class="citation" data-cites="BaayenRTs">(Baayen &amp; Milin, 2010)</span>,</p>
<p>You can also embed plots, for example:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(cars)</code></pre>
<figure>
<img src="figure/unnamed-chunk-1.png" alt="plot of chunk unnamed-chunk-1" /><figcaption>plot of chunk unnamed-chunk-1</figcaption>
</figure>
<h2 id="references">References</h2>
<p>Baayen, R. H., &amp; Milin, P. (2010). Analysing Reaction Times. <em>International Journal of Psychological Research</em>, <em>3</em>(2), 12–28.</p>
<p>Fernald, A., Swingley, D., &amp; Pinto, J. P. (2001). When Half a Word Is Enough: Infants Can Recognize Spoken Words Using Partial Phonetic Information. <em>Child Development</em>, <em>72</em>(4), 1003–1015. doi:10.1111/1467-8624.00331</p>
<p>Fernald, A., Zangl, R., Portillo, A. L., &amp; Marchman, V. A. (2008). Looking while listening: Using eye movements to monitor spoken language comprehension by infants and young children. In I. A. Sekerina, E. M. Fernández, &amp; H. Clahsen (Eds.), <em>Developmental Psycholinguistics: On-line Methods in Children’s Language Processing</em> (pp. 97–135). Amsterdam: John Benjamins Publishing Company.</p>
<p>Marchman, V. A., &amp; Fernald, A. (2008). Speed of word recognition and vocabulary knowledge in infancy predict cognitive and language outcomes in later childhood. <em>Developmental Science</em>, <em>11</em>(3), F9–F16. doi:10.1111/j.1467-7687.2008.00671.x</p>
</body>
</html>
